{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will import the Groove Midi Dataset and process it, and save it for easily being used in our pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SUPPRESSES THE TF WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the dataset already available in tensorflow_datasets, so let's load it first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tfds works in both Eager and Graph modes\n",
    "tf.enable_eager_execution() #not needed in TF V2, as it is already the default\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ipyparams\n",
    "\n",
    "from shutil import copy2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### NOTE:\n",
    " you can convert midi to note_sequence, two ways:\n",
    " 1. USE magenta.music.midi_to_note_sequence, BUT THIS will GIVE YOU A PICKLING ERROR\n",
    " 2. install note_seq (pip install note_seq) then use note_seq.midi_to_note_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/behzadhaki/.local/lib/python3.6/site-packages/magenta/music/note_sequence_io.py:60: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/behzadhaki/.local/lib/python3.6/site-packages/magenta/pipelines/statistics.py:132: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import magenta.music as mm \n",
    "import note_seq\n",
    "from magenta.models.music_vae import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.7\n"
     ]
    }
   ],
   "source": [
    "import magenta\n",
    "\n",
    "print (magenta.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Import OS and MIDI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groove MIDI Basics.ipynb     midi2HVO.ipynb\r\n",
      "GrooveMiditoTfExamples.ipynb midi_to_hvo_processing.ipynb\r\n",
      "Untitled1.ipynb              \u001b[34mmisc\u001b[m\u001b[m\r\n",
      "_24_12_2020__16:32.obj       \u001b[34mprocessed_dataset\u001b[m\u001b[m\r\n",
      "__init__.py                  \u001b[34mreference\u001b[m\u001b[m\r\n",
      "main.py                      \u001b[34msource_dataset\u001b[m\u001b[m\r\n",
      "midi2HVO-Updated-Copy1.ipynb temp.txt\r\n",
      "midi2HVO-Updated-Ver3.ipynb  \u001b[34mutils\u001b[m\u001b[m\r\n",
      "midi2HVO-Updated.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from visual_midi import Plotter\n",
    "\n",
    "from pretty_midi import PrettyMIDI\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "# Load midi_utils from storage folder\n",
    "import sys\n",
    "sys.path.append(\"utils\")\n",
    "!ls\n",
    "import midi_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_line_to_text(text, new_line):\n",
    "    return text+\"\\n\"+new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THE EXISTING DATASET WAS PROCESSED TO NOTESEQUENCE \n",
      "AND HVO FORMAT FROM GROOVEMIDI_2BAR_HUMANIZE SET \n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "info_text = \"\"\n",
    "info_text = add_line_to_text(info_text, \"THE EXISTING DATASET WAS PROCESSED TO NOTESEQUENCE \")\n",
    "info_text = add_line_to_text(info_text, \"AND HVO FORMAT FROM GROOVEMIDI_2BAR_HUMANIZE SET \")\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "\n",
    "print (info_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source (code directly copy pasted from): note_seq/drums_encoder_decoder\n",
    "\n",
    "# Default list of 9 drum types, where each type is represented by a list of\n",
    "# MIDI pitches for drum sounds belonging to that type. This default list\n",
    "# attempts to map all GM1 and GM2 drums onto a much smaller standard drum kit\n",
    "# based on drum sound and function.\n",
    "DEFAULT_DRUM_TYPE_PITCHES = [\n",
    "    # kick drum\n",
    "    [36, 35],\n",
    "\n",
    "    # snare drum\n",
    "    [38, 27, 28, 31, 32, 33, 34, 37, 39, 40, 56, 65, 66, 75, 85],\n",
    "\n",
    "    # closed hi-hat\n",
    "    [42, 44, 54, 68, 69, 70, 71, 73, 78, 80, 22],\n",
    "\n",
    "    # open hi-hat\n",
    "    [46, 67, 72, 74, 79, 81, 26],\n",
    "\n",
    "    # low tom\n",
    "    [45, 29, 41, 43, 61, 64, 84],\n",
    "\n",
    "    # mid tom\n",
    "    [48, 47, 60, 63, 77, 86, 87],\n",
    "\n",
    "    # high tom\n",
    "    [50, 30, 62, 76, 83],\n",
    "\n",
    "    # crash cymbal\n",
    "    [49, 52, 55, 57, 58],\n",
    "\n",
    "    # ride cymbal\n",
    "    [51, 53, 59, 82]\n",
    "] \n",
    "\n",
    "\n",
    "#Source (code directly copy pasted from): magenta/models/music_vae/data.py\n",
    "\n",
    "# 9 classes: kick, snare, closed_hh, open_hh, low_tom, mid_tom, hi_tom, crash,\n",
    "# ride\n",
    "REDUCED_DRUM_PITCH_CLASSES = DEFAULT_DRUM_TYPE_PITCHES\n",
    "# 61 classes: full General MIDI set\n",
    "FULL_DRUM_PITCH_CLASSES = [\n",
    "    [p] for p in  # pylint:disable=g-complex-comprehension\n",
    "    [36, 35, 38, 27, 28, 31, 32, 33, 34, 37, 39, 40, 56, 65, 66, 75, 85, 42, 44,\n",
    "     54, 68, 69, 70, 71, 73, 78, 80, 46, 67, 72, 74, 79, 81, 45, 29, 41, 61, 64,\n",
    "     84, 48, 47, 60, 63, 77, 86, 87, 50, 30, 43, 62, 76, 83, 49, 55, 57, 58, 51,\n",
    "     52, 53, 59, 82]\n",
    "]\n",
    "ROLAND_DRUM_PITCH_CLASSES = [\n",
    "    # kick drum\n",
    "    [36],\n",
    "    # snare drum\n",
    "    [38, 37, 40],\n",
    "    # closed hi-hat\n",
    "    [42, 22, 44],\n",
    "    # open hi-hat\n",
    "    [46, 26],\n",
    "    # low tom\n",
    "    [43, 58],\n",
    "    # mid tom\n",
    "    [47, 45],\n",
    "    # high tom\n",
    "    [50, 48],\n",
    "    # crash cymbal\n",
    "    [49, 52, 55, 57],\n",
    "    # ride cymbal\n",
    "    [51, 53, 59]\n",
    "]\n",
    "\n",
    "instruments = [\"kick\",\"snare\",\"hat_closed\",\"hat_open\",\"tom_low\",\"tom_mid\",\"tom_high\",\"cymbal_crash\",\"cymbal_ride\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD INFO TO TEXT FILE\n",
    "\n",
    "Mapping_text = \"\"\"DEFAULT_DRUM_TYPE_PITCHES = [\n",
    "    # kick drum\n",
    "    [36, 35],\n",
    "\n",
    "    # snare drum\n",
    "    [38, 27, 28, 31, 32, 33, 34, 37, 39, 40, 56, 65, 66, 75, 85],\n",
    "\n",
    "    # closed hi-hat\n",
    "    [42, 44, 54, 68, 69, 70, 71, 73, 78, 80, 22],\n",
    "\n",
    "    # open hi-hat\n",
    "    [46, 67, 72, 74, 79, 81, 26],\n",
    "\n",
    "    # low tom\n",
    "    [45, 29, 41, 43, 61, 64, 84],\n",
    "\n",
    "    # mid tom\n",
    "    [48, 47, 60, 63, 77, 86, 87],\n",
    "\n",
    "    # high tom\n",
    "    [50, 30, 62, 76, 83],\n",
    "\n",
    "    # crash cymbal\n",
    "    [49, 52, 55, 57, 58],\n",
    "\n",
    "    # ride cymbal\n",
    "    [51, 53, 59, 82]\n",
    "] \n",
    "\n",
    "\n",
    "#Source (code directly copy pasted from): magenta/models/music_vae/data.py\n",
    "\n",
    "# 9 classes: kick, snare, closed_hh, open_hh, low_tom, mid_tom, hi_tom, crash,\n",
    "# ride\n",
    "REDUCED_DRUM_PITCH_CLASSES = DEFAULT_DRUM_TYPE_PITCHES\n",
    "# 61 classes: full General MIDI set\n",
    "FULL_DRUM_PITCH_CLASSES = [\n",
    "    [p] for p in  # pylint:disable=g-complex-comprehension\n",
    "    [36, 35, 38, 27, 28, 31, 32, 33, 34, 37, 39, 40, 56, 65, 66, 75, 85, 42, 44,\n",
    "     54, 68, 69, 70, 71, 73, 78, 80, 46, 67, 72, 74, 79, 81, 45, 29, 41, 61, 64,\n",
    "     84, 48, 47, 60, 63, 77, 86, 87, 50, 30, 43, 62, 76, 83, 49, 55, 57, 58, 51,\n",
    "     52, 53, 59, 82]\n",
    "]\n",
    "ROLAND_DRUM_PITCH_CLASSES = [\n",
    "    # kick drum\n",
    "    [36],\n",
    "    # snare drum\n",
    "    [38, 37, 40],\n",
    "    # closed hi-hat\n",
    "    [42, 22, 44],\n",
    "    # open hi-hat\n",
    "    [46, 26],\n",
    "    # low tom\n",
    "    [43, 58],\n",
    "    # mid tom\n",
    "    [47, 45],\n",
    "    # high tom\n",
    "    [50, 48],\n",
    "    # crash cymbal\n",
    "    [49, 52, 55, 57],\n",
    "    # ride cymbal\n",
    "    [51, 53, 59]\n",
    "]\n",
    "\n",
    "instruments = [\"kick\",\"snare\",\"hat_closed\",\"hat_open\",\"tom_low\",\"tom_mid\",\"tom_high\",\"cymbal_crash\",\"cymbal_ride\"]\n",
    "\"\"\"\n",
    "\n",
    "info_text = add_line_to_text(info_text, Mapping_text)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Start With the 2bar-midionly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_unprocessed,dataset_train_info = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TRAIN,\n",
    "    try_gcs=True,\n",
    "    with_info=True)\n",
    "\n",
    "dataset_test_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TEST,\n",
    "    try_gcs=True)\n",
    "\n",
    "dataset_validation_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.VALIDATION,\n",
    "    try_gcs=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: TF DATASETS ARE PYTHON ITERABLES\n",
    "you can convert the dataset into a list or numpy array:\n",
    "\n",
    "   * List(dataset)\n",
    "   * tfds.as_numpy(dataset)\n",
    "    \n",
    "Lets see how many samples we've got in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of Batches Created for Training  --> 18163 \n",
      " \n"
     ]
    }
   ],
   "source": [
    " # Build your input pipeline\n",
    "\n",
    "\"\"\"dataset_train = dataset_train.batch(4).prefetch(\n",
    "    tf.data.experimental.AUTOTUNE)\"\"\"\n",
    "\n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_test  = dataset_test_unprocessed.batch(1)\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "\n",
    "temp = list(dataset_train)\n",
    "print(\"\\n Number of Batches Created for Training  --> %d \\n \" % len(temp)) #convert iterable to list\n",
    "del(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dict to store the processed data\n",
    "\n",
    "* Keys from Groove MIDI Dataset:\n",
    "    * bpm\n",
    "    * drummer\n",
    "    * id \n",
    "    * midi\n",
    "    * style\n",
    "    * time_signature\n",
    "    * type\n",
    "    \n",
    "* Keys for processed data\n",
    "    * note_sequence\n",
    "    * hvo (Hits, Velocity, Offsets)\n",
    "    * hv0 (Hits, Velocity, zero Offsets)\n",
    "    * h0o \n",
    "    * h00\n",
    "    * 0vo\n",
    "    * 0v0\n",
    "    * 00o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_converter=data.GrooveConverter(\n",
    "        split_bars=2, steps_per_quarter=4, quarters_per_bar=4,\n",
    "        max_tensors_per_notesequence=20, humanize=True,\n",
    "        pitch_classes=ROLAND_DRUM_PITCH_CLASSES,\n",
    "        inference_pitch_classes=REDUCED_DRUM_PITCH_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18163\n"
     ]
    }
   ],
   "source": [
    "print(len(list(dataset_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>138</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>27.872308</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>102</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>37.691158</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>105</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>36.351218</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>86</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>44.716543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>80</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>47.987500</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "   bpm beat_type time_signature  \\\n",
       "0  138      beat            4-4   \n",
       "1  102      beat            4-4   \n",
       "2  105      beat            4-4   \n",
       "3   86      beat            4-4   \n",
       "4   80      beat            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename   duration split  \n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('source_dataset/groove/info.csv', delimiter = ',')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drummer1/eval_session'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataframe[dataframe.id == \"drummer1/eval_session/1\"][\"session\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_append(dictionary, key, vals):\n",
    "    # Appends a value or a list of values to a key in a dictionary\n",
    "    \n",
    "    # if the values for a key are not a list, they are converted to a list and then extended with vals\n",
    "    dictionary[key]=list(dictionary[key]) if not isinstance(dictionary[key], list) else dictionary[key]\n",
    "    \n",
    "    # if vals is a single value (not a list), it's converted to a list so as to be iterable\n",
    "    vals = [vals] if not isinstance(vals, list) else vals\n",
    "        \n",
    "    # append new values \n",
    "    for val in vals:\n",
    "        dictionary[key].append(val)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def convert_groove_midi_dataset(dataset, csv_dataframe_info=None):\n",
    "    \n",
    "    dataset_dict_processed = dict()\n",
    "    dataset_dict_processed.update({\n",
    "        \"drummer\":[],\n",
    "        \"session\":[],\n",
    "        \"loop_id\":[],  # the id of the recording from which the loop is extracted\n",
    "        \"master_id\":[], # the id of the recording from which the loop is extracted\n",
    "        \"style_primary\":[],\n",
    "        \"style_secondary\":[],\n",
    "        \"bpm\":[],\n",
    "        \"beat_type\":[],\n",
    "        \"time_signature\":[],\n",
    "        \"full_midi_filename\":[],\n",
    "        \"full_audio_filename\":[],\n",
    "        \"midi\":[],\n",
    "        \"note_sequence\":[],\n",
    "        \"hvo\":[],\n",
    "    })\n",
    "\n",
    "    count = 0 \n",
    "    \n",
    "    \n",
    "    for features in dataset:\n",
    "        \n",
    "        #midi, ID, style_primary, style_secondary,  = features[\"midi\"], features[\"id\"], features[\"style\"][\"primary\"], features[\"style\"][\"secondary\"]\n",
    "\n",
    "        # Features readily available in dataset\n",
    "        \n",
    "        \n",
    "        # Features to be extracted from the dataset\n",
    "        \n",
    "        note_sequence = note_seq.midi_to_note_sequence(tfds.as_numpy(features[\"midi\"][0]))\n",
    "        hvo = data_converter.to_tensors(note_sequence).outputs\n",
    "        if hvo: # if hvo is None, don't add it to the dictionary\n",
    "            if not csv_dataframe_info.empty:\n",
    "\n",
    "                # Master ID for the Loop\n",
    "                main_id = features[\"id\"].numpy()[0].decode(\"utf-8\").split(\":\")[0]\n",
    "\n",
    "                # Get the relevant series from the dataframe\n",
    "                df = csv_dataframe_info[csv_dataframe_info.id == main_id]\n",
    "\n",
    "            #dict_append(dataset_dict_processed, \"bpm_master\", df[\"bpm\"].to_numpy()[0])\n",
    "\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"drummer\", df[\"drummer\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"session\", df[\"session\"].to_numpy()[0].split(\"/\")[-1])\n",
    "                dict_append(dataset_dict_processed, \"loop_id\", features[\"id\"].numpy()[0].decode(\"utf-8\"))\n",
    "                dict_append(dataset_dict_processed, \"master_id\", main_id)\n",
    "\n",
    "                style_full = df[\"style\"].to_numpy()[0]\n",
    "                style_primary = style_full.split(\"/\")[0]\n",
    "                dict_append(dataset_dict_processed, \"style_primary\", style_primary)\n",
    "\n",
    "                if \"/\" in style_full:\n",
    "                    style_secondary = style_full.split(\"/\")[1]\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", style_secondary)\n",
    "                else:\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", [\"None\"])\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"bpm\", df[\"bpm\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"beat_type\", df[\"beat_type\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"time_signature\", df[\"time_signature\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"full_midi_filename\", df[\"midi_filename\"].to_numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"full_audio_filename\", df[\"audio_filename\"].to_numpy()[0])\n",
    "                #note_sequence = mm.midi_to_note_sequence(tfds.as_numpy(features[\"midi\"][0]))\n",
    "                dict_append(dataset_dict_processed, \"midi\", features[\"midi\"].numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"note_sequence\", [note_sequence])\n",
    "\n",
    "            dict_append(dataset_dict_processed, \"hvo\", hvo[0])\n",
    "            #h, v, o = np.hsplit(hvo[0],3)\n",
    "            #dict_append(dataset_dict_processed, \"h\", h)\n",
    "            #dict_append(dataset_dict_processed, \"v\", v)\n",
    "            #dict_append(dataset_dict_processed, \"o\", o)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            pass \n",
    "            \"\"\"dict_append(dataset_dict_processed, \"hvo\", [None]) \n",
    "            dict_append(dataset_dict_processed, \"h\", [None])\n",
    "            dict_append(dataset_dict_processed, \"v\", [None])\n",
    "            dict_append(dataset_dict_processed, \"o\", [None])\"\"\"\n",
    "            \n",
    "    return dataset_dict_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 3.79 s, total: 1min 51s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Process Training Set\n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_train_processed = convert_groove_midi_dataset(dataset_train, dataframe)\n",
    "\n",
    "# Process Test Set\n",
    "dataset_test = dataset_test_unprocessed.batch(1)\n",
    "dataset_test_processed = convert_groove_midi_dataset(dataset_test, dataframe)\n",
    "\n",
    "# Process Validation Set\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "dataset_validation_processed = convert_groove_midi_dataset(dataset_validation, dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature drummer --> Size = 16389\n",
      "Feature session --> Size = 16389\n",
      "Feature loop_id --> Size = 16389\n",
      "Feature master_id --> Size = 16389\n",
      "Feature style_primary --> Size = 16389\n",
      "Feature style_secondary --> Size = 16389\n",
      "Feature bpm --> Size = 16389\n",
      "Feature beat_type --> Size = 16389\n",
      "Feature time_signature --> Size = 16389\n",
      "Feature full_midi_filename --> Size = 16389\n",
      "Feature full_audio_filename --> Size = 16389\n",
      "Feature midi --> Size = 16389\n",
      "Feature note_sequence --> Size = 16389\n",
      "Feature hvo --> Size = 16389\n",
      "Feature drummer --> Size = 2064\n",
      "Feature session --> Size = 2064\n",
      "Feature loop_id --> Size = 2064\n",
      "Feature master_id --> Size = 2064\n",
      "Feature style_primary --> Size = 2064\n",
      "Feature style_secondary --> Size = 2064\n",
      "Feature bpm --> Size = 2064\n",
      "Feature beat_type --> Size = 2064\n",
      "Feature time_signature --> Size = 2064\n",
      "Feature full_midi_filename --> Size = 2064\n",
      "Feature full_audio_filename --> Size = 2064\n",
      "Feature midi --> Size = 2064\n",
      "Feature note_sequence --> Size = 2064\n",
      "Feature hvo --> Size = 2064\n",
      "Feature drummer --> Size = 2039\n",
      "Feature session --> Size = 2039\n",
      "Feature loop_id --> Size = 2039\n",
      "Feature master_id --> Size = 2039\n",
      "Feature style_primary --> Size = 2039\n",
      "Feature style_secondary --> Size = 2039\n",
      "Feature bpm --> Size = 2039\n",
      "Feature beat_type --> Size = 2039\n",
      "Feature time_signature --> Size = 2039\n",
      "Feature full_midi_filename --> Size = 2039\n",
      "Feature full_audio_filename --> Size = 2039\n",
      "Feature midi --> Size = 2039\n",
      "Feature note_sequence --> Size = 2039\n",
      "Feature hvo --> Size = 2039\n",
      "CPU times: user 1.34 ms, sys: 999 µs, total: 2.34 ms\n",
      "Wall time: 1.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "\n",
    "# Let's do a preliminary check of the training set\n",
    "for key in dataset_train_processed.keys():\n",
    "    info_text = add_line_to_text(info_text, \"Training Set\\n\\n\\n\")\n",
    "    info_text = add_line_to_text(info_text, \"Feature %s --> Size = %d\" % (key, len(dataset_train_processed[key])))\n",
    "    print(\"Feature %s --> Size = %d\" % (key, len(dataset_train_processed[key])))\n",
    "\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "\n",
    "# Let's do a preliminary check of the test set\n",
    "for key in dataset_test_processed.keys():\n",
    "    info_text = add_line_to_text(info_text, \"Test Set\\n\\n\\n\")\n",
    "    info_text = add_line_to_text(info_text, \"Feature %s --> Size = %d\" % (key, len(dataset_test_processed[key])))\n",
    "    print(\"Feature %s --> Size = %d\" % (key, len(dataset_test_processed[key])))\n",
    "\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "\n",
    "# Let's do a preliminary check of the validation set\n",
    "for key in dataset_validation_processed.keys():\n",
    "    info_text = add_line_to_text(info_text, \"Validation Set\\n\\n\\n\")\n",
    "    info_text = add_line_to_text(info_text, \"Feature %s --> Size = %d\" % (key, len(dataset_validation_processed[key])))    \n",
    "    print(\"Feature %s --> Size = %d\" % (key, len(dataset_validation_processed[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dictionary_by_key (dictionary_to_sort, key_used_to_sort):\n",
    "    # sorts a dictionary according to the list within a given key\n",
    "    sorted_ids=np.argsort(dictionary_to_sort[key_used_to_sort])\n",
    "    for key in dictionary_to_sort.keys():\n",
    "        dictionary_to_sort[key]=[dictionary_to_sort[key][i] for i in sorted_ids]\n",
    "    return dictionary_to_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the sets using ids\n",
    "dataset_train_processed = sort_dictionary_by_key(dataset_train_processed, \"loop_id\")\n",
    "dataset_test_processed = sort_dictionary_by_key(dataset_test_processed, \"loop_id\")\n",
    "dataset_validation_processed = sort_dictionary_by_key(dataset_validation_processed, \"loop_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP INTO A PICKLE FILE\n",
    "def store_dataset_as_pickle(dataset_list, \n",
    "                            filename_list, \n",
    "                            root_dir = \"processed_dataset\",\n",
    "                            append_datetime=True, \n",
    "                            features_with_separate_picklefile = [\"hvo\", \"midi\", \"note_seq\"]\n",
    "                           ):\n",
    "\n",
    "    #filename = filename.split(\".obj\")[0]\n",
    "    path = root_dir\n",
    "    \n",
    "    if append_datetime:\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_at_%H_%M_hrs\")\n",
    "    else:\n",
    "        dt_string =\"\"\n",
    "        \n",
    "    path = os.path.join(path, \"Processed_On_\"+dt_string)\n",
    "    \n",
    "    if not os.path.exists (path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    currentNotebook = ipyparams.notebook_name\n",
    "    print(\"Copying Source Code from %s to %s\" % (os.path.join(os.getcwd(), currentNotebook), path))\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    copy2(os.path.join(os.getcwd(), currentNotebook), path) \n",
    "    \n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "\n",
    "        subdirectory = os.path.join(path, filename_list[i])\n",
    "        if not os.path.exists (subdirectory):\n",
    "            os.makedirs(subdirectory)\n",
    "            \n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Processing %s folder\" % subdirectory)\n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Create Metadata File\n",
    "        csv_dataframe = pd.DataFrame()\n",
    "        \n",
    "        for k in dataset.keys():\n",
    "            if k not in features_with_separate_picklefile:\n",
    "                csv_dataframe[k] = dataset[k]\n",
    "        \n",
    "        csv_dataframe.to_csv(os.path.join(subdirectory, \"metadata.csv\"))\n",
    "        \n",
    "        print(\"Metadata created!\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        for feature in features_with_separate_picklefile:\n",
    "            if feature in dataset.keys():\n",
    "                dataset_filehandler = open(os.path.join(subdirectory, \"%s_data.obj\"%feature),\"wb\")\n",
    "                pickle.dump(dataset[feature],  dataset_filehandler)\n",
    "                dataset_filehandler.close()\n",
    "                print(\"feature %s pickled at %s\" % (feature, os.path.join(subdirectory, \"%s.obj\"%filename_list[i].split(\".\")[0])))\n",
    "                print(\"-\"*100)\n",
    "\n",
    "            else:\n",
    "                 raise Warning(\"Feature is not available: \", feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Source Code from /Users/behzadhaki/PycharmProjects/GrooveMIDIPreprocessing/midi2HVO-Updated-Ver3.ipynb to processed_dataset/Processed_On_17_01_2021_at_01_51_hrs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_train folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature hvo pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature midi pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_test folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature hvo pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature midi pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_validation folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature hvo pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature midi pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "info_text = add_line_to_text(info_text, \"-\"*50)\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_dataset/Processed_On_17_01_2021_at_01_51_hrs/GrooveMIDI_processed_train/hvo_data.obj\n",
      "Dataset Size: 16389 \n",
      " Features:  ['Unnamed: 0', 'drummer', 'session', 'loop_id', 'master_id', 'style_primary', 'style_secondary', 'bpm', 'beat_type', 'time_signature', 'full_midi_filename', 'full_audio_filename']\n"
     ]
    }
   ],
   "source": [
    "source_path = \"processed_dataset/Processed_On_17_01_2021_at_01_51_hrs\"\n",
    "print(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"))\n",
    "train_file = open(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"),'rb')\n",
    "train_set = pickle.load(train_file)\n",
    "metadata = pd.read_csv(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"metadata.csv\"))\n",
    "\n",
    "features_in_metadata = list(metadata.columns)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "\n",
    "print(\"Dataset Size: %d \\n Features: \" % dataset_size, features_in_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Number: 8493, Primary Style: brazilian-samba, Secondary Style: latin\n"
     ]
    }
   ],
   "source": [
    "ix =  int(np.random.random_sample()*dataset_size)\n",
    "print(\"Sample Number: %d, Primary Style: %s, Secondary Style: %s\" % (ix, \n",
    "                                                                     metadata[\"style_secondary\"][ix], \n",
    "                                                                     metadata[\"style_primary\"][ix])\n",
    "     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
